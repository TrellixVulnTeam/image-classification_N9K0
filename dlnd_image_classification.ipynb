{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 图像分类\n",
    "\n",
    "在此项目中，你将对 [CIFAR-10 数据集](https://www.cs.toronto.edu/~kriz/cifar.html) 中的图片进行分类。该数据集包含飞机、猫狗和其他物体。你需要预处理这些图片，然后用所有样本训练一个卷积神经网络。图片需要标准化（normalized），标签需要采用 one-hot 编码。你需要应用所学的知识构建卷积的、最大池化（max pooling）、丢弃（dropout）和完全连接（fully connected）的层。最后，你需要在样本图片上看到神经网络的预测结果。\n",
    "\n",
    "\n",
    "## 获取数据\n",
    "\n",
    "请运行以下单元，以下载 [CIFAR-10 数据集（Python版）](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/input/cifar-10/python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 探索数据\n",
    "\n",
    "该数据集分成了几部分／批次（batches），以免你的机器在计算时内存不足。CIFAR-10 数据集包含 5 个部分，名称分别为 `data_batch_1`、`data_batch_2`，以此类推。每个部分都包含以下某个类别的标签和图片：\n",
    "\n",
    "* 飞机\n",
    "* 汽车\n",
    "* 鸟类\n",
    "* 猫\n",
    "* 鹿\n",
    "* 狗\n",
    "* 青蛙\n",
    "* 马\n",
    "* 船只\n",
    "* 卡车\n",
    "\n",
    "了解数据集也是对数据进行预测的必经步骤。你可以通过更改 `batch_id` 和 `sample_id` 探索下面的代码单元。`batch_id` 是数据集一个部分的 ID（1 到 5）。`sample_id` 是该部分中图片和标签对（label pair）的 ID。\n",
    "\n",
    "问问你自己：“可能的标签有哪些？”、“图片数据的值范围是多少？”、“标签是按顺序排列，还是随机排列的？”。思考类似的问题，有助于你预处理数据，并使预测结果更准确。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 50:\n",
      "Image - Min Value: 8 Max Value: 243\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 9 Name: truck\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x229b4b504a8>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 50\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现预处理函数\n",
    "\n",
    "### 标准化\n",
    "\n",
    "在下面的单元中，实现 `normalize` 函数，传入图片数据 `x`，并返回标准化 Numpy 数组。值应该在 0 到 1 的范围内（含 0 和 1）。返回对象应该和 `x` 的形状一样。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    norm = np.linalg.norm(x)\n",
    "    if norm == 0:\n",
    "        return x\n",
    "    return x/norm\n",
    "    \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot 编码\n",
    "\n",
    "和之前的代码单元一样，你将为预处理实现一个函数。这次，你将实现 `one_hot_encode` 函数。输入，也就是 `x`，是一个标签列表。实现该函数，以返回为 one_hot 编码的 Numpy 数组的标签列表。标签的可能值为 0 到 9。每次调用 `one_hot_encode` 时，对于每个值，one_hot 编码函数应该返回相同的编码。确保将编码映射保存到该函数外面。\n",
    "\n",
    "提示：不要重复发明轮子。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  1.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  1.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  1.]]\n",
      "==================\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]]\n",
      "==================\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    ohe = np.identity(10)[x]\n",
    "    print(ohe)\n",
    "    print('==================')\n",
    "    return ohe\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机化数据\n",
    "\n",
    "之前探索数据时，你已经了解到，样本的顺序是随机的。再随机化一次也不会有什么关系，但是对于这个数据集没有必要。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理所有数据并保存\n",
    "\n",
    "运行下方的代码单元，将预处理所有 CIFAR-10 数据，并保存到文件中。下面的代码还使用了 10% 的训练数据，用来验证。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  1.]\n",
      " [ 0.  0.  0. ...,  0.  0.  1.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  1.]]\n",
      "==================\n",
      "[[ 0.  1.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  1.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 1.  0.  0. ...,  0.  0.  0.]]\n",
      "==================\n",
      "[[ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 1.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "==================\n",
      "[[ 1.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 1.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  1.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "==================\n",
      "[[ 0.  1.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  1.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "==================\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  1. ...,  0.  0.  0.]\n",
      " [ 0.  0.  1. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  1.]\n",
      " [ 0.  1.  0. ...,  0.  0.  0.]\n",
      " [ 0.  1.  0. ...,  0.  0.  0.]]\n",
      "==================\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  0.  0. ...,  0.  1.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  1.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  1.  0.  0.]]\n",
      "==================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "\n",
    "这是你的第一个检查点。如果你什么时候决定再回到该记事本，或需要重新启动该记事本，你可以从这里开始。预处理的数据已保存到本地。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建网络\n",
    "\n",
    "对于该神经网络，你需要将每层都构建为一个函数。你看到的大部分代码都位于函数外面。要更全面地测试你的代码，我们需要你将每层放入一个函数中。这样使我们能够提供更好的反馈，并使用我们的统一测试检测简单的错误，然后再提交项目。\n",
    "\n",
    ">**注意**：如果你觉得每周很难抽出足够的时间学习这门课程，我们为此项目提供了一个小捷径。对于接下来的几个问题，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 程序包中的类来构建每个层级，但是“卷积和最大池化层级”部分的层级除外。TF Layers 和 Keras 及 TFLearn 层级类似，因此很容易学会。\n",
    "\n",
    ">但是，如果你想充分利用这门课程，请尝试自己解决所有问题，不使用 TF Layers 程序包中的任何类。你依然可以使用其他程序包中的类，这些类和你在 TF Layers 中的类名称是一样的！例如，你可以使用 TF Neural Network 版本的 `conv2d` 类 [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d)，而不是 TF Layers 版本的 `conv2d` 类 [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d)。\n",
    "\n",
    "我们开始吧！\n",
    "\n",
    "\n",
    "### 输入\n",
    "\n",
    "神经网络需要读取图片数据、one-hot 编码标签和丢弃保留概率（dropout keep probability）。请实现以下函数：\n",
    "\n",
    "* 实现 `neural_net_image_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * 使用 `image_shape` 设置形状，部分大小设为 `None`\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"x\" 命名\n",
    "* 实现 `neural_net_label_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * 使用 `n_classes` 设置形状，部分大小设为 `None`\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"y\" 命名\n",
    "* 实现 `neural_net_keep_prob_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)，用于丢弃保留概率\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"keep_prob\" 命名\n",
    "\n",
    "这些名称将在项目结束时，用于加载保存的模型。\n",
    "\n",
    "注意：TensorFlow 中的 `None` 表示形状可以是动态大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n",
      "Image Input Tests Passed.\n",
      "10\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    print(image_shape)\n",
    "    return tf.placeholder(tf.float32,[None,*image_shape],name='x')\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    print(n_classes)\n",
    "    return tf.placeholder(tf.float32,[None,n_classes],name='y')\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32,name='keep_prob')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积和最大池化层\n",
    "\n",
    "卷积层级适合处理图片。对于此代码单元，你应该实现函数 `conv2d_maxpool` 以便应用卷积然后进行最大池化：\n",
    "\n",
    "* 使用 `conv_ksize`、`conv_num_outputs` 和 `x_tensor` 的形状创建权重（weight）和偏置（bias）。\n",
    "* 使用权重和 `conv_strides` 对 `x_tensor` 应用卷积。\n",
    " * 建议使用我们建议的间距（padding），当然也可以使用任何其他间距。\n",
    "* 添加偏置\n",
    "* 向卷积中添加非线性激活（nonlinear activation）\n",
    "* 使用 `pool_ksize` 和 `pool_strides` 应用最大池化\n",
    " * 建议使用我们建议的间距（padding），当然也可以使用任何其他间距。\n",
    "\n",
    "**注意**：对于**此层**，**请勿使用** [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers)，但是仍然可以使用 TensorFlow 的 [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) 包。对于所有**其他层**，你依然可以使用快捷方法。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4)\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "#     weight\n",
    "    weight=tf.Variable(tf.truncated_normal([conv_ksize[0],conv_ksize[1],x_tensor.get_shape().as_list()[-1],conv_num_outputs]))\n",
    "#     bias\n",
    "    bias=tf.Variable(tf.zeros([conv_num_outputs]))\n",
    "    \n",
    "    #Convolution\n",
    "    print(conv_strides)\n",
    "    strides=[1,*conv_strides,1]\n",
    "    output=tf.nn.conv2d(x_tensor,weight,strides,padding='SAME')\n",
    "    activation=tf.nn.relu(tf.nn.bias_add(output,bias))\n",
    "    \n",
    "        \n",
    "    ksize=[1,*pool_ksize,1]\n",
    "    strides=[1,*pool_strides,1]\n",
    "    maxpool=tf.nn.max_pool(activation,ksize,strides,padding='SAME')\n",
    "    return maxpool\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 扁平化层\n",
    "\n",
    "实现 `flatten` 函数，将 `x_tensor` 的维度从四维张量（4-D tensor）变成二维张量。输出应该是形状（*部分大小（Batch Size）*，*扁平化图片大小（Flattened Image Size）*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Flatten/flatten/Reshape:0\", shape=(?, 1800), dtype=float32)\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "#     s=x_tensor.get_shape().as_list()\n",
    "#     print(s)\n",
    "#     d=s[1]*s[2]*s[3]\n",
    "#     print(d)\n",
    "#     return tf.reshape(x_tensor,[-1,d])\n",
    "    fl=tf.contrib.layers.flatten(x_tensor)\n",
    "    print(fl)\n",
    "    return fl \n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全连接层\n",
    "\n",
    "实现 `fully_conn` 函数，以向 `x_tensor` 应用完全连接的层级，形状为（*部分大小（Batch Size）*，*num_outputs*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "#     s=x_tensor.get_shape().as_list()[1]\n",
    "#     print(s)\n",
    "#     weight=tf.Variable(tf.truncated_normal([s,num_outputs]))\n",
    "#     bias=tf.Variable(tf.zeros(num_outputs))\n",
    "    \n",
    "#     fc=tf.add(tf.matmul(x_tensor,w),b)\n",
    "\n",
    "    fc=tf.contrib.layers.fully_connected(x_tensor, num_outputs=num_outputs)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return tf.nn.relu(fc)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输出层\n",
    "\n",
    "实现 `output` 函数，向 x_tensor 应用完全连接的层级，形状为（*部分大小（Batch Size）*，*num_outputs*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。\n",
    "\n",
    "**注意**：该层级不应应用 Activation、softmax 或交叉熵（cross entropy）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "#     s=x_tensor.get_shape().as_list()[1]\n",
    "#     print(s)\n",
    "    \n",
    "#     w=tf.Variable(tf.truncated_normal([s,num_outputs]))\n",
    "#     b=tf.Variable(tf.zeros(num_outputs))    \n",
    "    \n",
    "#     return tf.add(tf.matmul(x_tensor,w),b)\n",
    "\n",
    "    return tf.layers.dense(x_tensor, num_outputs)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建卷积模型\n",
    "\n",
    "实现函数 `conv_net`， 创建卷积神经网络模型。该函数传入一批图片 `x`，并输出对数（logits）。使用你在上方创建的层创建此模型：\n",
    "\n",
    "* 应用 1、2 或 3 个卷积和最大池化层（Convolution and Max Pool layers）\n",
    "* 应用一个扁平层（Flatten Layer）\n",
    "* 应用 1、2 或 3 个完全连接层（Fully Connected Layers）\n",
    "* 应用一个输出层（Output Layer）\n",
    "* 返回输出\n",
    "* 使用 `keep_prob` 向模型中的一个或多个层应用 [TensorFlow 的 Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n",
      "10\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "Tensor(\"Flatten/flatten/Reshape:0\", shape=(?, 4096), dtype=float32)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "Tensor(\"Flatten_1/flatten/Reshape:0\", shape=(?, 4096), dtype=float32)\n",
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    \n",
    "    conv = conv2d_maxpool(x,32,(8,8),(1,1),(2,2),(2,2))\n",
    "    conv = conv2d_maxpool(conv,64,(4,4),(1,1),(2,2),(2,2))\n",
    "    conv = conv2d_maxpool(conv,256,(2,2),(1,1),(2,2),(2,2))\n",
    "    \n",
    "    \n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    \n",
    "    fl=flatten(conv)\n",
    "    \n",
    "    \n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    \n",
    "    fc = fully_conn(fl, 512)\n",
    "    fc = fully_conn(fc, 64)\n",
    "    fc = tf.nn.dropout(fc, keep_prob)\n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    \n",
    "    out=tf.nn.dropout(output(fc,10),keep_prob)\n",
    "    \n",
    "    # TODO: return output\n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练神经网络\n",
    "\n",
    "### 单次优化\n",
    "\n",
    "实现函数 `train_neural_network` 以进行单次优化（single optimization）。该优化应该使用 `optimizer` 优化 `session`，其中 `feed_dict` 具有以下参数：\n",
    "\n",
    "* `x` 表示图片输入\n",
    "* `y` 表示标签\n",
    "* `keep_prob` 表示丢弃的保留率\n",
    "\n",
    "每个部分都会调用该函数，所以 `tf.global_variables_initializer()` 已经被调用。\n",
    "\n",
    "注意：不需要返回任何内容。该函数只是用来优化神经网络。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer,feed_dict={x:feature_batch,y:label_batch,keep_prob:keep_probability})\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 显示数据\n",
    "\n",
    "实现函数 `print_stats` 以输出损失和验证准确率。使用全局变量 `valid_features` 和 `valid_labels` 计算验证准确率。使用保留率 `1.0` 计算损失和验证准确率（loss and validation accuracy）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    # loss\n",
    "    \n",
    "    loss=session.run(cost,feed_dict={x:feature_batch,y:label_batch,keep_prob:1.0})\n",
    "    print('loss=',loss)\n",
    "    \n",
    "    # valid accuracy\n",
    "    valid_acc=session.run(accuracy,feed_dict={x:valid_features,y:valid_labels,keep_prob:1.0})\n",
    "    print('accuracy=',valid_acc)\n",
    "    \n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 超参数\n",
    "\n",
    "调试以下超参数：\n",
    "* 设置 `epochs` 表示神经网络停止学习或开始过拟合的迭代次数\n",
    "* 设置 `batch_size`，表示机器内存允许的部分最大体积。大部分人设为以下常见内存大小：\n",
    "\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* 设置 `keep_probability` 表示使用丢弃时保留节点的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 30\n",
    "batch_size = 1024\n",
    "keep_probability = 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在单个 CIFAR-10 部分上训练\n",
    "\n",
    "我们先用单个部分，而不是用所有的 CIFAR-10 批次训练神经网络。这样可以节省时间，并对模型进行迭代，以提高准确率。最终验证准确率达到 50% 或以上之后，在下一部分对所有数据运行模型。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  loss= 2.25883\n",
      "accuracy= 0.1412\n",
      "Epoch  2, CIFAR-10 Batch 1:  loss= 2.14185\n",
      "accuracy= 0.1472\n",
      "Epoch  3, CIFAR-10 Batch 1:  loss= 2.05646\n",
      "accuracy= 0.2098\n",
      "Epoch  4, CIFAR-10 Batch 1:  loss= 1.98322\n",
      "accuracy= 0.2366\n",
      "Epoch  5, CIFAR-10 Batch 1:  loss= 1.94449\n",
      "accuracy= 0.2456\n",
      "Epoch  6, CIFAR-10 Batch 1:  loss= 1.8621\n",
      "accuracy= 0.3074\n",
      "Epoch  7, CIFAR-10 Batch 1:  loss= 1.81523\n",
      "accuracy= 0.3138\n",
      "Epoch  8, CIFAR-10 Batch 1:  loss= 1.75502\n",
      "accuracy= 0.3274\n",
      "Epoch  9, CIFAR-10 Batch 1:  loss= 1.71073\n",
      "accuracy= 0.3418\n",
      "Epoch 10, CIFAR-10 Batch 1:  loss= 1.66788\n",
      "accuracy= 0.361\n",
      "Epoch 11, CIFAR-10 Batch 1:  loss= 1.64741\n",
      "accuracy= 0.3654\n",
      "Epoch 12, CIFAR-10 Batch 1:  loss= 1.58253\n",
      "accuracy= 0.4092\n",
      "Epoch 13, CIFAR-10 Batch 1:  loss= 1.55697\n",
      "accuracy= 0.4078\n",
      "Epoch 14, CIFAR-10 Batch 1:  loss= 1.52312\n",
      "accuracy= 0.43\n",
      "Epoch 15, CIFAR-10 Batch 1:  loss= 1.51976\n",
      "accuracy= 0.4048\n",
      "Epoch 16, CIFAR-10 Batch 1:  loss= 1.44927\n",
      "accuracy= 0.448\n",
      "Epoch 17, CIFAR-10 Batch 1:  loss= 1.43866\n",
      "accuracy= 0.4228\n",
      "Epoch 18, CIFAR-10 Batch 1:  loss= 1.42404\n",
      "accuracy= 0.435\n",
      "Epoch 19, CIFAR-10 Batch 1:  loss= 1.3938\n",
      "accuracy= 0.4376\n",
      "Epoch 20, CIFAR-10 Batch 1:  loss= 1.35085\n",
      "accuracy= 0.4544\n",
      "Epoch 21, CIFAR-10 Batch 1:  loss= 1.33483\n",
      "accuracy= 0.4718\n",
      "Epoch 22, CIFAR-10 Batch 1:  loss= 1.36318\n",
      "accuracy= 0.4308\n",
      "Epoch 23, CIFAR-10 Batch 1:  loss= 1.30618\n",
      "accuracy= 0.4648\n",
      "Epoch 24, CIFAR-10 Batch 1:  loss= 1.30189\n",
      "accuracy= 0.4696\n",
      "Epoch 25, CIFAR-10 Batch 1:  loss= 1.2735\n",
      "accuracy= 0.4936\n",
      "Epoch 26, CIFAR-10 Batch 1:  loss= 1.25769\n",
      "accuracy= 0.4756\n",
      "Epoch 27, CIFAR-10 Batch 1:  loss= 1.25761\n",
      "accuracy= 0.4556\n",
      "Epoch 28, CIFAR-10 Batch 1:  loss= 1.20117\n",
      "accuracy= 0.4844\n",
      "Epoch 29, CIFAR-10 Batch 1:  loss= 1.20554\n",
      "accuracy= 0.4708\n",
      "Epoch 30, CIFAR-10 Batch 1:  loss= 1.19\n",
      "accuracy= 0.4728\n",
      "129.07016451625407\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "t0 = time.clock()\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "print (time.clock() - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 完全训练模型\n",
    "\n",
    "现在，单个 CIFAR-10 部分的准确率已经不错了，试试所有五个部分吧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  loss= 2.2327\n",
      "accuracy= 0.1778\n",
      "Epoch  1, CIFAR-10 Batch 2:  loss= 2.08075\n",
      "accuracy= 0.2466\n",
      "Epoch  1, CIFAR-10 Batch 3:  loss= 1.97309\n",
      "accuracy= 0.2788\n",
      "Epoch  1, CIFAR-10 Batch 4:  loss= 1.89765\n",
      "accuracy= 0.2802\n",
      "Epoch  1, CIFAR-10 Batch 5:  loss= 1.83244\n",
      "accuracy= 0.3002\n",
      "Epoch  2, CIFAR-10 Batch 1:  loss= 1.79846\n",
      "accuracy= 0.3376\n",
      "Epoch  2, CIFAR-10 Batch 2:  loss= 1.7407\n",
      "accuracy= 0.349\n",
      "Epoch  2, CIFAR-10 Batch 3:  loss= 1.66911\n",
      "accuracy= 0.3756\n",
      "Epoch  2, CIFAR-10 Batch 4:  loss= 1.6442\n",
      "accuracy= 0.3802\n",
      "Epoch  2, CIFAR-10 Batch 5:  loss= 1.62084\n",
      "accuracy= 0.3986\n",
      "Epoch  3, CIFAR-10 Batch 1:  loss= 1.57411\n",
      "accuracy= 0.3928\n",
      "Epoch  3, CIFAR-10 Batch 2:  loss= 1.54339\n",
      "accuracy= 0.4344\n",
      "Epoch  3, CIFAR-10 Batch 3:  loss= 1.54644\n",
      "accuracy= 0.392\n",
      "Epoch  3, CIFAR-10 Batch 4:  loss= 1.49852\n",
      "accuracy= 0.4302\n",
      "Epoch  3, CIFAR-10 Batch 5:  loss= 1.51093\n",
      "accuracy= 0.4236\n",
      "Epoch  4, CIFAR-10 Batch 1:  loss= 1.4786\n",
      "accuracy= 0.431\n",
      "Epoch  4, CIFAR-10 Batch 2:  loss= 1.46459\n",
      "accuracy= 0.45\n",
      "Epoch  4, CIFAR-10 Batch 3:  loss= 1.47183\n",
      "accuracy= 0.4226\n",
      "Epoch  4, CIFAR-10 Batch 4:  loss= 1.40568\n",
      "accuracy= 0.4602\n",
      "Epoch  4, CIFAR-10 Batch 5:  loss= 1.42135\n",
      "accuracy= 0.4566\n",
      "Epoch  5, CIFAR-10 Batch 1:  loss= 1.40929\n",
      "accuracy= 0.4532\n",
      "Epoch  5, CIFAR-10 Batch 2:  loss= 1.38167\n",
      "accuracy= 0.4792\n",
      "Epoch  5, CIFAR-10 Batch 3:  loss= 1.35902\n",
      "accuracy= 0.4594\n",
      "Epoch  5, CIFAR-10 Batch 4:  loss= 1.34501\n",
      "accuracy= 0.4834\n",
      "Epoch  5, CIFAR-10 Batch 5:  loss= 1.34117\n",
      "accuracy= 0.485\n",
      "Epoch  6, CIFAR-10 Batch 1:  loss= 1.35454\n",
      "accuracy= 0.476\n",
      "Epoch  6, CIFAR-10 Batch 2:  loss= 1.34667\n",
      "accuracy= 0.5014\n",
      "Epoch  6, CIFAR-10 Batch 3:  loss= 1.31665\n",
      "accuracy= 0.4766\n",
      "Epoch  6, CIFAR-10 Batch 4:  loss= 1.29823\n",
      "accuracy= 0.5022\n",
      "Epoch  6, CIFAR-10 Batch 5:  loss= 1.30766\n",
      "accuracy= 0.487\n",
      "Epoch  7, CIFAR-10 Batch 1:  loss= 1.31181\n",
      "accuracy= 0.495\n",
      "Epoch  7, CIFAR-10 Batch 2:  loss= 1.29132\n",
      "accuracy= 0.508\n",
      "Epoch  7, CIFAR-10 Batch 3:  loss= 1.27072\n",
      "accuracy= 0.4848\n",
      "Epoch  7, CIFAR-10 Batch 4:  loss= 1.25889\n",
      "accuracy= 0.4928\n",
      "Epoch  7, CIFAR-10 Batch 5:  loss= 1.26843\n",
      "accuracy= 0.4974\n",
      "Epoch  8, CIFAR-10 Batch 1:  loss= 1.28281\n",
      "accuracy= 0.522\n",
      "Epoch  8, CIFAR-10 Batch 2:  loss= 1.25397\n",
      "accuracy= 0.4994\n",
      "Epoch  8, CIFAR-10 Batch 3:  loss= 1.24669\n",
      "accuracy= 0.4868\n",
      "Epoch  8, CIFAR-10 Batch 4:  loss= 1.22721\n",
      "accuracy= 0.5042\n",
      "Epoch  8, CIFAR-10 Batch 5:  loss= 1.25332\n",
      "accuracy= 0.4936\n",
      "Epoch  9, CIFAR-10 Batch 1:  loss= 1.23568\n",
      "accuracy= 0.5196\n",
      "Epoch  9, CIFAR-10 Batch 2:  loss= 1.2162\n",
      "accuracy= 0.5146\n",
      "Epoch  9, CIFAR-10 Batch 3:  loss= 1.21182\n",
      "accuracy= 0.5066\n",
      "Epoch  9, CIFAR-10 Batch 4:  loss= 1.18669\n",
      "accuracy= 0.5136\n",
      "Epoch  9, CIFAR-10 Batch 5:  loss= 1.19575\n",
      "accuracy= 0.5036\n",
      "Epoch 10, CIFAR-10 Batch 1:  loss= 1.21504\n",
      "accuracy= 0.52\n",
      "Epoch 10, CIFAR-10 Batch 2:  loss= 1.20684\n",
      "accuracy= 0.5304\n",
      "Epoch 10, CIFAR-10 Batch 3:  loss= 1.16372\n",
      "accuracy= 0.5198\n",
      "Epoch 10, CIFAR-10 Batch 4:  loss= 1.14908\n",
      "accuracy= 0.5176\n",
      "Epoch 10, CIFAR-10 Batch 5:  loss= 1.17064\n",
      "accuracy= 0.532\n",
      "Epoch 11, CIFAR-10 Batch 1:  loss= 1.18958\n",
      "accuracy= 0.5328\n",
      "Epoch 11, CIFAR-10 Batch 2:  loss= 1.16055\n",
      "accuracy= 0.5254\n",
      "Epoch 11, CIFAR-10 Batch 3:  loss= 1.14513\n",
      "accuracy= 0.5112\n",
      "Epoch 11, CIFAR-10 Batch 4:  loss= 1.11808\n",
      "accuracy= 0.5336\n",
      "Epoch 11, CIFAR-10 Batch 5:  loss= 1.15051\n",
      "accuracy= 0.5356\n",
      "Epoch 12, CIFAR-10 Batch 1:  loss= 1.15544\n",
      "accuracy= 0.5352\n",
      "Epoch 12, CIFAR-10 Batch 2:  loss= 1.14513\n",
      "accuracy= 0.539\n",
      "Epoch 12, CIFAR-10 Batch 3:  loss= 1.13441\n",
      "accuracy= 0.531\n",
      "Epoch 12, CIFAR-10 Batch 4:  loss= 1.0982\n",
      "accuracy= 0.534\n",
      "Epoch 12, CIFAR-10 Batch 5:  loss= 1.11436\n",
      "accuracy= 0.5364\n",
      "Epoch 13, CIFAR-10 Batch 1:  loss= 1.14521\n",
      "accuracy= 0.5406\n",
      "Epoch 13, CIFAR-10 Batch 2:  loss= 1.11882\n",
      "accuracy= 0.5356\n",
      "Epoch 13, CIFAR-10 Batch 3:  loss= 1.14288\n",
      "accuracy= 0.506\n",
      "Epoch 13, CIFAR-10 Batch 4:  loss= 1.0849\n",
      "accuracy= 0.5338\n",
      "Epoch 13, CIFAR-10 Batch 5:  loss= 1.1042\n",
      "accuracy= 0.5366\n",
      "Epoch 14, CIFAR-10 Batch 1:  loss= 1.11603\n",
      "accuracy= 0.5446\n",
      "Epoch 14, CIFAR-10 Batch 2:  loss= 1.0974\n",
      "accuracy= 0.543\n",
      "Epoch 14, CIFAR-10 Batch 3:  loss= 1.11496\n",
      "accuracy= 0.52\n",
      "Epoch 14, CIFAR-10 Batch 4:  loss= 1.06749\n",
      "accuracy= 0.5352\n",
      "Epoch 14, CIFAR-10 Batch 5:  loss= 1.0865\n",
      "accuracy= 0.5488\n",
      "Epoch 15, CIFAR-10 Batch 1:  loss= 1.09222\n",
      "accuracy= 0.538\n",
      "Epoch 15, CIFAR-10 Batch 2:  loss= 1.07864\n",
      "accuracy= 0.5298\n",
      "Epoch 15, CIFAR-10 Batch 3:  loss= 1.0524\n",
      "accuracy= 0.541\n",
      "Epoch 15, CIFAR-10 Batch 4:  loss= 1.01656\n",
      "accuracy= 0.5514\n",
      "Epoch 15, CIFAR-10 Batch 5:  loss= 1.05892\n",
      "accuracy= 0.5454\n",
      "Epoch 16, CIFAR-10 Batch 1:  loss= 1.07624\n",
      "accuracy= 0.557\n",
      "Epoch 16, CIFAR-10 Batch 2:  loss= 1.06452\n",
      "accuracy= 0.5446\n",
      "Epoch 16, CIFAR-10 Batch 3:  loss= 1.04228\n",
      "accuracy= 0.547\n",
      "Epoch 16, CIFAR-10 Batch 4:  loss= 1.01853\n",
      "accuracy= 0.56\n",
      "Epoch 16, CIFAR-10 Batch 5:  loss= 1.0582\n",
      "accuracy= 0.5486\n",
      "Epoch 17, CIFAR-10 Batch 1:  loss= 1.06371\n",
      "accuracy= 0.5446\n",
      "Epoch 17, CIFAR-10 Batch 2:  loss= 1.05225\n",
      "accuracy= 0.5438\n",
      "Epoch 17, CIFAR-10 Batch 3:  loss= 1.02962\n",
      "accuracy= 0.5688\n",
      "Epoch 17, CIFAR-10 Batch 4:  loss= 1.01285\n",
      "accuracy= 0.5416\n",
      "Epoch 17, CIFAR-10 Batch 5:  loss= 1.08527\n",
      "accuracy= 0.5662\n",
      "Epoch 18, CIFAR-10 Batch 1:  loss= 1.05816\n",
      "accuracy= 0.5316\n",
      "Epoch 18, CIFAR-10 Batch 2:  loss= 1.02288\n",
      "accuracy= 0.5534\n",
      "Epoch 18, CIFAR-10 Batch 3:  loss= 1.01926\n",
      "accuracy= 0.58\n",
      "Epoch 18, CIFAR-10 Batch 4:  loss= 0.990478\n",
      "accuracy= 0.5706\n",
      "Epoch 18, CIFAR-10 Batch 5:  loss= 0.987606\n",
      "accuracy= 0.5712\n",
      "Epoch 19, CIFAR-10 Batch 1:  loss= 1.00793\n",
      "accuracy= 0.5626\n",
      "Epoch 19, CIFAR-10 Batch 2:  loss= 1.03449\n",
      "accuracy= 0.532\n",
      "Epoch 19, CIFAR-10 Batch 3:  loss= 0.992924\n",
      "accuracy= 0.569\n",
      "Epoch 19, CIFAR-10 Batch 4:  loss= 0.963105\n",
      "accuracy= 0.5672\n",
      "Epoch 19, CIFAR-10 Batch 5:  loss= 0.97212\n",
      "accuracy= 0.563\n",
      "Epoch 20, CIFAR-10 Batch 1:  loss= 0.986135\n",
      "accuracy= 0.5656\n",
      "Epoch 20, CIFAR-10 Batch 2:  loss= 1.00957\n",
      "accuracy= 0.5392\n",
      "Epoch 20, CIFAR-10 Batch 3:  loss= 0.980469\n",
      "accuracy= 0.5784\n",
      "Epoch 20, CIFAR-10 Batch 4:  loss= 0.961602\n",
      "accuracy= 0.5392\n",
      "Epoch 20, CIFAR-10 Batch 5:  loss= 0.971416\n",
      "accuracy= 0.564\n",
      "Epoch 21, CIFAR-10 Batch 1:  loss= 1.00087\n",
      "accuracy= 0.5688\n",
      "Epoch 21, CIFAR-10 Batch 2:  loss= 0.993341\n",
      "accuracy= 0.544\n",
      "Epoch 21, CIFAR-10 Batch 3:  loss= 0.937467\n",
      "accuracy= 0.5872\n",
      "Epoch 21, CIFAR-10 Batch 4:  loss= 0.931877\n",
      "accuracy= 0.5696\n",
      "Epoch 21, CIFAR-10 Batch 5:  loss= 0.945559\n",
      "accuracy= 0.569\n",
      "Epoch 22, CIFAR-10 Batch 1:  loss= 0.956321\n",
      "accuracy= 0.5802\n",
      "Epoch 22, CIFAR-10 Batch 2:  loss= 0.984751\n",
      "accuracy= 0.5438\n",
      "Epoch 22, CIFAR-10 Batch 3:  loss= 0.938601\n",
      "accuracy= 0.5796\n",
      "Epoch 22, CIFAR-10 Batch 4:  loss= 0.935863\n",
      "accuracy= 0.579\n",
      "Epoch 22, CIFAR-10 Batch 5:  loss= 0.932595\n",
      "accuracy= 0.5748\n",
      "Epoch 23, CIFAR-10 Batch 1:  loss= 0.981838\n",
      "accuracy= 0.5722\n",
      "Epoch 23, CIFAR-10 Batch 2:  loss= 0.958174\n",
      "accuracy= 0.5456\n",
      "Epoch 23, CIFAR-10 Batch 3:  loss= 0.940444\n",
      "accuracy= 0.5564\n",
      "Epoch 23, CIFAR-10 Batch 4:  loss= 0.917869\n",
      "accuracy= 0.5632\n",
      "Epoch 23, CIFAR-10 Batch 5:  loss= 0.918903\n",
      "accuracy= 0.5752\n",
      "Epoch 24, CIFAR-10 Batch 1:  loss= 0.927938\n",
      "accuracy= 0.5936\n",
      "Epoch 24, CIFAR-10 Batch 2:  loss= 0.921918\n",
      "accuracy= 0.5552\n",
      "Epoch 24, CIFAR-10 Batch 3:  loss= 0.893581\n",
      "accuracy= 0.5776\n",
      "Epoch 24, CIFAR-10 Batch 4:  loss= 0.904502\n",
      "accuracy= 0.5634\n",
      "Epoch 24, CIFAR-10 Batch 5:  loss= 0.887144\n",
      "accuracy= 0.5902\n",
      "Epoch 25, CIFAR-10 Batch 1:  loss= 0.941608\n",
      "accuracy= 0.5912\n",
      "Epoch 25, CIFAR-10 Batch 2:  loss= 0.904547\n",
      "accuracy= 0.5782\n",
      "Epoch 25, CIFAR-10 Batch 3:  loss= 0.877168\n",
      "accuracy= 0.5644\n",
      "Epoch 25, CIFAR-10 Batch 4:  loss= 0.904642\n",
      "accuracy= 0.567\n",
      "Epoch 25, CIFAR-10 Batch 5:  loss= 0.905347\n",
      "accuracy= 0.5762\n",
      "Epoch 26, CIFAR-10 Batch 1:  loss= 0.917044\n",
      "accuracy= 0.5952\n",
      "Epoch 26, CIFAR-10 Batch 2:  loss= 0.888078\n",
      "accuracy= 0.5658\n",
      "Epoch 26, CIFAR-10 Batch 3:  loss= 0.853451\n",
      "accuracy= 0.5856\n",
      "Epoch 26, CIFAR-10 Batch 4:  loss= 0.863399\n",
      "accuracy= 0.5668\n",
      "Epoch 26, CIFAR-10 Batch 5:  loss= 0.866241\n",
      "accuracy= 0.5876\n",
      "Epoch 27, CIFAR-10 Batch 1:  loss= 0.924193\n",
      "accuracy= 0.5792\n",
      "Epoch 27, CIFAR-10 Batch 2:  loss= 0.892428\n",
      "accuracy= 0.5834\n",
      "Epoch 27, CIFAR-10 Batch 3:  loss= 0.87423\n",
      "accuracy= 0.575\n",
      "Epoch 27, CIFAR-10 Batch 4:  loss= 0.851931\n",
      "accuracy= 0.5818\n",
      "Epoch 27, CIFAR-10 Batch 5:  loss= 0.854441\n",
      "accuracy= 0.5848\n",
      "Epoch 28, CIFAR-10 Batch 1:  loss= 0.862566\n",
      "accuracy= 0.5928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, CIFAR-10 Batch 2:  loss= 0.87202\n",
      "accuracy= 0.5776\n",
      "Epoch 28, CIFAR-10 Batch 3:  loss= 0.868653\n",
      "accuracy= 0.5846\n",
      "Epoch 28, CIFAR-10 Batch 4:  loss= 0.841682\n",
      "accuracy= 0.579\n",
      "Epoch 28, CIFAR-10 Batch 5:  loss= 0.823948\n",
      "accuracy= 0.566\n",
      "Epoch 29, CIFAR-10 Batch 1:  loss= 0.886584\n",
      "accuracy= 0.586\n",
      "Epoch 29, CIFAR-10 Batch 2:  loss= 0.851953\n",
      "accuracy= 0.5822\n",
      "Epoch 29, CIFAR-10 Batch 3:  loss= 0.825356\n",
      "accuracy= 0.5744\n",
      "Epoch 29, CIFAR-10 Batch 4:  loss= 0.831522\n",
      "accuracy= 0.5862\n",
      "Epoch 29, CIFAR-10 Batch 5:  loss= 0.798439\n",
      "accuracy= 0.5742\n",
      "Epoch 30, CIFAR-10 Batch 1:  loss= 0.847834\n",
      "accuracy= 0.5956\n",
      "Epoch 30, CIFAR-10 Batch 2:  loss= 0.834378\n",
      "accuracy= 0.5842\n",
      "Epoch 30, CIFAR-10 Batch 3:  loss= 0.783065\n",
      "accuracy= 0.5904\n",
      "Epoch 30, CIFAR-10 Batch 4:  loss= 0.819018\n",
      "accuracy= 0.5746\n",
      "Epoch 30, CIFAR-10 Batch 5:  loss= 0.793719\n",
      "accuracy= 0.5766\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "\n",
    "模型已保存到本地。\n",
    "\n",
    "## 测试模型\n",
    "\n",
    "利用测试数据集测试你的模型。这将是最终的准确率。你的准确率应该高于 50%。如果没达到，请继续调整模型结构和参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./image_classification\n",
      "Testing Accuracy: 0.6048030912876129\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nktQYjiVJkqTm/wMUjspZhiJ/gwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x229be4c7278>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 为何准确率只有50-80%？\n",
    "\n",
    "你可能想问，为何准确率不能更高了？首先，对于简单的 CNN 网络来说，50% 已经不低了。纯粹猜测的准确率为10%。但是，你可能注意到有人的准确率[远远超过 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130)。这是因为我们还没有介绍所有的神经网络知识。我们还需要掌握一些其他技巧。\n",
    "\n",
    "## 提交项目\n",
    "\n",
    "提交项目时，确保先运行所有单元，然后再保存记事本。将 notebook 文件另存为“dlnd_image_classification.ipynb”，再在目录 \"File\" -> \"Download as\" 另存为 HTML 格式。请在提交的项目中包含 “helper.py” 和 “problem_unittests.py” 文件。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 回答：#### \n",
    "由于我都是用的是默认的初始参数比如默认的标准差，默认的初始值，也没有调整激活函数,并没有根据实际情况对参数做设置所以在有限的次数中很难超过50%更别说80%了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
